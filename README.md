# Dynamic Pricing using Multi-Armed Bandits

This project implements a generic *dynamic pricing engine* using *Reinforcement Learning (Multi-Armed Bandit algorithms)* to learn the optimal selling price over time without labeled historical data.

---

## ðŸš€ Why Bandits for Pricing?

Traditional ML requires labeled data â€” in pricing we often *do not know in advance* which price will perform the best.  
A bandit model *learns while earning* â€” it simultaneously explores new prices and exploits the best observed one.

---

## ðŸ“Œ Algorithms Implemented

- *Îµ-Greedy*
- *UCB (Upper Confidence Bound)*
- *Thompson Sampling*

All three are compared on the same environment to measure regret and revenue lift.

---

## ðŸ§° Tech Stack

- Python
- Numpy
- Jupyter Notebook (analysis & experiments)

(Flask / Streamlit deployment will be added later)

---

## ðŸ“‚ Planned Folder Structure
